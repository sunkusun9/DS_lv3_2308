{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f1d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209faf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 모듈 설정\n",
    "# 참고용 차트를 출력하기 위함\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c0422",
   "metadata": {},
   "source": [
    "# 문제 6\n",
    "\n",
    "[Kaggle 형] train_prob.csv로 문제 failure 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 failure가 1일 확률 예측하여 다음과 같은 형식의 answer6.csv를 만들어라. \n",
    "\n",
    "측정 지표는 AUC(area under of ROC curve)이다. id 는 테스트 케이스의 id 이고, failure에는 failure가 1이 될 확률이다.\n",
    "\n",
    "id,failure\n",
    "\n",
    "16115, 0.1\n",
    "\n",
    "16116, 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422cead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test를 읽어 옵니다.\n",
    "df_train = pd.read_csv('train_prob.csv', index_col='id')\n",
    "df_test =  pd.read_csv('test_prob.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207a07b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 처리하기 전에,\n",
    "# 결측 여부가 failure를 예측하는데, 유용할 만하다고 도출된\n",
    "# measurement_3, measurement_5의 결측 여부만 남깁니다.\n",
    "df_train[['na_1', 'na_2']] = df_train[['measurement_3', 'measurement_5']].isna()\n",
    "df_test[['na_1', 'na_2']] = df_test[['measurement_3', 'measurement_5']].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6cac8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    5765\n",
       "E    5343\n",
       "B    5250\n",
       "A    5100\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab48a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    5112\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train에 등장하지 않은 수준이 나옵니다.\n",
    "df_test['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3433c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_code에 test에는 train에 등장하지 않은 수준이 나옵니다.\n",
    "# product_code에 구분하여 적용될 수 있도록, \n",
    "# train, test를 합쳐 모델을 만듭니다.\n",
    "# measurement_3~9 17은 선형관계에 있다고 주어진 사실이므로\n",
    "# 여기서 train_test를 합치는 건 검증 방법에 대한 정당성에는 \n",
    "# 이슈가 없다고 판단됩니다.\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "s_imp = pd.concat([\n",
    "            df_train[['product_code'] + X_imp],\n",
    "            df_test[['product_code'] + X_imp]\n",
    "        ]).groupby('product_code').apply(\n",
    "            lambda x: IterativeImputer(estimator = LinearRegression(), random_state = 123).fit(x[X_imp])\n",
    "        )\n",
    "df_train[X_imp] = df_train.groupby('product_code').apply(\n",
    "    lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    ")\n",
    "df_test[X_imp] = df_test.groupby('product_code').apply(\n",
    "    lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2700b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 같은 사유로\n",
    "# train, test를 합쳐 통계를 만들고,\n",
    "# product_code 별로 평균을 내어 보완하는 것이\n",
    "# 최선의 선택이라 판단되어 train_test를 합쳐서\n",
    "# 평균을 내어 결측치를 처리합니다.\n",
    "\n",
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_mean = pd.concat([\n",
    "            df_train[['product_code'] + X_mean],\n",
    "            df_test[['product_code'] + X_mean]\n",
    "        ]).groupby('product_code')[X_mean].agg('mean')\n",
    "\n",
    "df_train[X_mean] = df_train.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))\n",
    "df_test[X_mean] = df_test.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c1ebce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['loading'] = df_train['loading'].fillna(df_train['loading'].mean())\n",
    "# loading은 train에서의 평균으로 결측치를 처리합니다.\n",
    "df_test['loading'] = df_test['loading'].fillna(df_train['loading'].mean())\n",
    "df_train.isna().sum().sum(), df_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc8db4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통으로 사용할 만한 요소입니다.\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dbc437c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.57912402, 0.58968448, 0.57221316, 0.61180378, 0.57922945]),\n",
       " 0.5864109791862437,\n",
       " 0.01386911859118403)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 모델을 만들어 봅니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading'] + ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "score = cross_val_score(clf_lr, df_train[X_lr], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "score_mean, score_std = np.mean(score), np.std(score)\n",
    "score, score_mean, score_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0220daae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline 모델에 대한 제출 파일을 만듭니다.\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "clf_lr.fit(df_train[X_lr], df_train['failure'])\n",
    "pd.DataFrame(\n",
    "    clf_lr.predict_proba(df_test[X_lr])[:, 1],\n",
    "    index=df_test.index, columns=['failure']\n",
    ").to_csv('answer6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c34493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5891265737410073"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id' )\n",
    "roc_auc_score(df_ans['failure'], clf_lr.predict_proba(df_test[X_lr])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eba9de4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58840017, 0.5909264 , 0.57725538, 0.61231432, 0.58375591]),\n",
       " 0.590530435171204,\n",
       " 0.011843596922835509)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 3번에서 도출한 속성 선택법을 사용합니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "X_lr = ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17', 'na_1']\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "score = cross_val_score(clf_lr, df_train[X_lr], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "score_mean, score_std = np.mean(score), np.std(score)\n",
    "score, score_mean, score_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c0ff945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5883988309352517"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제로는 Baseline 보다 떨어집니다.\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "clf_lr.fit(df_train[X_lr], df_train['failure'])\n",
    "roc_auc_score(df_ans['failure'], clf_lr.predict_proba(df_test[X_lr])[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575139d",
   "metadata": {},
   "source": [
    "Baseline 모델에 보다 개선점이 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "154c2a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 문제에서 속성 선택법에 대한 힌트가 없을 때를 가정하고 \n",
    "# 빠르게 속성선택법의 효과성을 살펴 봅니다.\n",
    "\n",
    "# 속성선택기 설정을 합니다.\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True) # 5겹 층화교차검증(5-Fold stratified cross validation)\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator = LogisticRegression(solver='lbfgs'),\n",
    "    k_features='best',# 최적의 성능을 보이는 입력 변수의 조합을 찾는다. \n",
    "    forward=True, # 전진 선택\n",
    "    floating=False, # 선택했던 변수를 제외하지 않는다. \n",
    "    cv = cv,\n",
    "    scoring='roc_auc' # _score 끝나면: _score를 뺍니다 ex) roc_auc_score -  roc_auc else neg_ ex) mean_squared_error - neg_mean_squared_error\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea1622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.57899225, 0.59057654, 0.5762483 , 0.60776799, 0.58230052]),\n",
       " 0.5871771208338508,\n",
       " 0.01136443907079411)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(),  ['loading'] + ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "# 속성 선택기를 pipeline 중간에 넣습니다.\n",
    "clf_lr = make_pipeline(ct, sfs, LogisticRegression(solver='lbfgs'))\n",
    "score = cross_val_score(clf_lr, df_train[X_lr], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "score_mean, score_std = np.mean(score), np.std(score)\n",
    "score, score_mean, score_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f31ea",
   "metadata": {},
   "source": [
    "Baseline 보다는 좋은 효과를 보입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b2e6bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('std',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  ['loading', 'measurement_0',\n",
       "                                                   'measurement_1',\n",
       "                                                   'measurement_2',\n",
       "                                                   'measurement_3',\n",
       "                                                   'measurement_4',\n",
       "                                                   'measurement_5',\n",
       "                                                   'measurement_6',\n",
       "                                                   'measurem...\n",
       "                                           k_features='best', n_jobs=1,\n",
       "                                           pre_dispatch='2*n_jobs',\n",
       "                                           scoring='roc_auc', verbose=0)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제에서 힌트가 없더라도, \n",
    "# 수행할 만하다면 mlxtend.feature_selection.SequentialFeatureSelector를 통해 전진/후진 속성선택을 적용할 수 있습니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(),  ['loading'] + ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr = make_pipeline(ct, sfs, LogisticRegression(solver='lbfgs'))\n",
    "clf_lr.fit(df_train[X_lr], df_train['failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4b1988b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '2', '5', '10', '15', '18', '19')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스를 통해 모델에 접근할 있습니다.\n",
    "# 모델에 접근하여 선택된 속성을 봅니다.\n",
    "# 상위 버젼의 sklearn이라면 온전한 속성명을 볼 수 있지만, 여기서는 인덱스로 확인 됩니다.\n",
    "clf_lr[1].k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03aa34fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58193117, 0.58917288, 0.57115364, 0.61208951, 0.58374711]),\n",
       " 0.5876188608180666,\n",
       " 0.013562239996136743)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading']),\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)) , ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "score = cross_val_score(clf_lr, df_train[X_lr], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "score_mean, score_std = np.mean(score), np.std(score)\n",
    "score, score_mean, score_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02cacc",
   "metadata": {},
   "source": [
    "Baseline 보다는 좋은 성능을 냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f90a364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5907120053956835"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr.fit(df_train[X_lr], df_train['failure'])\n",
    "roc_auc_score(df_ans['failure'], clf_lr.predict_proba(df_test[X_lr])[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fe9d24",
   "metadata": {},
   "source": [
    "Test 데이터에 대해서도 Baseline 보다는 좋은 성능을 냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa4d43",
   "metadata": {},
   "source": [
    "## 다른 모델들도 만들어 봅니다.\n",
    "\n",
    "참고삼아 다른 모델도 만들어 봅니다.\n",
    "\n",
    "그리고 이들도 마지막 앙상블 모델에 넣어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6353a72e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.59016944, 0.59366441, 0.57107023, 0.59631159, 0.57999249]),\n",
       " 0.586241632091449)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoosting 모델을 만들어 봅니다.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_gb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct_3 = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_gb)\n",
    "])\n",
    "clf_gb = make_pipeline(ct_3, GradientBoostingClassifier(\n",
    "    n_estimators=100, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "scores_ = cross_val_score(clf_gb, df_train[X_gb], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e72b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58337509, 0.59098856, 0.56659036, 0.59663707, 0.57633855]),\n",
       " 0.5827859261718101)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier 모델도 만들어 봅니다. (좀더 튜닝했습니다.)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_rf = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct_4 = ColumnTransformer([\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)), ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['loading', 'na_1', 'na_2'])\n",
    "])\n",
    "clf_rf = make_pipeline(ct_4, RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=7, min_samples_split= 512, random_state=123\n",
    "))\n",
    "scores_ = cross_val_score(clf_rf, df_train[X_rf], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fc4c752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58961081, 0.59397   , 0.5726996 , 0.59593267, 0.57998353]),\n",
       " 0.5864393237715635)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb로 모델을 만들어 봅니다.\n",
    "import xgboost as xgb\n",
    "X_xgb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct_5 = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_xgb)\n",
    "])\n",
    "clf_xgb = make_pipeline(ct_3, xgb.XGBClassifier(\n",
    "    n_estimators=150, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "scores_ = cross_val_score(clf_xgb, df_train[X_xgb], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea03bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading'] + ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# 속성 선택 + LogisticRegression 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "X_lr = ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17', 'na_1']\n",
    "clf_lr_2 = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# PCA + LogisticRegression 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading']),\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)) , ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr_3 = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# GradientBoosting 모델입니다.\n",
    "X_gb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_gb)\n",
    "])\n",
    "clf_gb = make_pipeline(ct, GradientBoostingClassifier(\n",
    "    n_estimators=100, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "\n",
    "# Random Forest 입니다.\n",
    "X_rf = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)), ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['loading', 'na_1', 'na_2'])\n",
    "])\n",
    "clf_rf = make_pipeline(ct, RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=7, min_samples_split= 512, random_state=123\n",
    "))\n",
    "\n",
    "# XGBoost 입니다.\n",
    "X_xgb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_xgb)\n",
    "])\n",
    "clf_xgb = make_pipeline(ct, xgb.XGBClassifier(\n",
    "    n_estimators=150, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86ecf2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58729852, 0.5942948 , 0.57348838, 0.6093423 , 0.58242302]),\n",
       " 0.5893694056158315)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "X_vt = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)] \n",
    "# 모두 앙상블을 해봅니다.\n",
    "clf_vt = VotingClassifier(\n",
    "    [\n",
    "        ('lr', clf_lr), # 모든 속성 사용 모델입니다\n",
    "        ('lr_2', clf_lr_2), # 속성 선택을 통한 모델(Baseline)\n",
    "        ('lr_3', clf_lr_3), # PCA + 속성 선택 모델 \n",
    "        ('gb', clf_gb), # GradientBoost\n",
    "        ('rf', clf_rf), # Random Forest 입니다.\n",
    "        ('xgb', clf_xgb) # xgboost\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "scores_ = cross_val_score(clf_vt, df_train[X_vt], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "score = np.mean(scores_)\n",
    "scores_, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4018fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5927969874100719"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_vt.fit(df_train[X_lr], df_train['failure'])\n",
    "roc_auc_score(df_ans['failure'], clf_vt.predict_proba(df_test[X_lr])[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175a521",
   "metadata": {},
   "source": [
    "성능 향상이 보입니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4052a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
